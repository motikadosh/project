{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=4, suppress=True)\n",
    "\n",
    "# Freeze seed - Must be called before import of Keras!\n",
    "seed = 12345\n",
    "np.random.seed(seed)\n",
    "print(\"Seed state - {seed}\".format(seed=seed))\n",
    "\n",
    "import cv2\n",
    "from visualize import OrthoData, imshow\n",
    "%matplotlib inline\n",
    "\n",
    "from utils import get_files_with_ext\n",
    "\n",
    "project_base_dir = '/home/moti/cg/project'\n",
    "\n",
    "data_sessions_outputs = os.path.join(project_base_dir, 'sessions_outputs')\n",
    "model_sessions_outputs = os.path.join(project_base_dir, 'meshNet/sessions_outputs')\n",
    "\n",
    "data_dir = os.path.join(data_sessions_outputs, 'berlinRoi_-1600_-800_1600_1600_GridStep10')\n",
    "\n",
    "results_dir = os.path.join(project_base_dir, 'meshNet', 'results')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nearest_neighbour(y_true, y_pred, k=5):\n",
    "    from scipy import spatial\n",
    "    tree = spatial.cKDTree(y_true)\n",
    "    return tree.query(y_pred, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nn_dist = None\n",
    "\n",
    "def get_sorted_array_idx(data, is_interpolation):\n",
    "    global nn_dist\n",
    "    grid_step = data['grid_step']\n",
    "    \n",
    "    if is_interpolation:\n",
    "        print(\"Geo-Interpolation...\")\n",
    "        \n",
    "        y_test_true = data['y_test_true']\n",
    "        y_test_pred = data['y_test_pred']\n",
    "\n",
    "        x_manhattan_distance = abs(y_test_true[:, 0] - y_test_pred[:, 0]) // grid_step\n",
    "        y_manhattan_distance = abs(y_test_true[:, 1] - y_test_pred[:, 1]) // grid_step\n",
    "        xy_manhattan_distance = x_manhattan_distance + y_manhattan_distance\n",
    "    \n",
    "        from visualize import plot_hist\n",
    "        %matplotlib inline\n",
    "    \n",
    "        k = int(max(xy_manhattan_distance))\n",
    "        plot_hist(xy_manhattan_distance, normed=False, bins=k, title='Manhattan distance of ' + str(len(y_test_true)) + \" test samples\", ylabel=None, show=True, save_path=None)\n",
    "\n",
    "        # np.argsort([2,1,3,4,5]) is [1 0 2 3 4], i.e. from small to big.\n",
    "        sorted_array_idx = np.argsort(xy_manhattan_distance)\n",
    "    else:\n",
    "        print(\"Geo-Matching...\")\n",
    "        \n",
    "        y_train_true = data['y_train_true']\n",
    "        y_train_pred = data['y_train_pred']\n",
    "\n",
    "        k = 1000\n",
    "        nn = nearest_neighbour(y_train_true, y_train_pred, k=k)\n",
    "\n",
    "        nn_dist = np.zeros(len(nn[0]), dtype=int)\n",
    "        for idx, neighbors in enumerate(nn[1]):\n",
    "            for j in xrange(k):\n",
    "                if neighbors[j] == idx:\n",
    "                    nn_dist[idx] = j + 1\n",
    "                    break\n",
    "    #     print(nn_dist)\n",
    "\n",
    "        nn_dist[nn_dist == 0] = k + 1\n",
    "#         for i in xrange(1, k + 2):\n",
    "#             print(i, ':', sum(nn_dist == i))\n",
    "\n",
    "        # np.argsort([2,1,3,4,5]) is [1 0 2 3 4], i.e. from small to big.\n",
    "        sorted_array_idx = np.argsort(nn_dist)\n",
    "\n",
    "    return sorted_array_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, errno\n",
    "def mkdirs(newdir, mode=0777):\n",
    "    try: os.makedirs(newdir, mode)\n",
    "    except OSError, err:\n",
    "        # Reraise the error unless it's about an already existing directory \n",
    "        if err.errno != errno.EEXIST or not os.path.isdir(newdir): \n",
    "            raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pexpect\n",
    "\n",
    "def scp_expect(src, dst):\n",
    "    try:\n",
    "        var_password = \"Shamir#2017!\"\n",
    "        var_command = \"scp -r \" + src + \" \" + dst\n",
    "    #     \" arik@194.153.101.19:/mnt/arik_2T_usb/project/sessions_outputs/berlinRoi_-1600_-800_1600_1600_GridStep10/gridStep10_third_2/train/-800/-850_-350\" + \\\n",
    "    #     \" /home/moti/cg/project/sessions_outputs/berlinRoi_-1600_-800_1600_1600_GridStep10/gridStep10_third_2/train/-800/-850_-350/..\"\n",
    "\n",
    "        #make sure in the above command that username and hostname are according to your server\n",
    "        var_child = pexpect.spawn(var_command, timeout=60)\n",
    "        i = var_child.expect([\"arik@194.153.101.19's password: \", pexpect.EOF])\n",
    "\n",
    "        if i == 0: # send password                \n",
    "            var_child.sendline(var_password)\n",
    "            var_child.expect(pexpect.EOF)\n",
    "        elif i == 1: \n",
    "            print(\"Got the key or connection timeout\")\n",
    "            pass\n",
    "    except Exception as e:\n",
    "        print(\"Oops Something went wrong buddy\")\n",
    "        print(e)\n",
    "\n",
    "#     print(\"scp done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def verify_images_availability(file_urls, idx_list):\n",
    "        \n",
    "    for idx in idx_list:\n",
    "#         if idx > len(file_urls):\n",
    "#             print(\"idx:\", idx, \"exceeds number of samples. skipping...\")\n",
    "#             continue  # idx_list might not be ordered\n",
    "            \n",
    "        f = file_urls[idx]\n",
    "\n",
    "#         print('idx:', idx, ', file:', f)\n",
    "        f_local = f.replace('/mnt/arik_2T_usb/project/sessions_outputs', data_sessions_outputs)\n",
    "        if not os.path.isfile(f_local):\n",
    "            print('idx:', idx, f_local, \"does not exist, copying from remote...\")\n",
    "\n",
    "            dst_dir = os.path.split(f_local)[0] + os.sep + os.pardir\n",
    "            mkdirs(dst_dir)\n",
    "\n",
    "            src_dir = os.path.split(f)[0]\n",
    "            scp_expect(\"arik@194.153.101.19:\" + src_dir, dst_dir)\n",
    "            print('idx:', idx, ', done copy from remote\\n')\n",
    "        else:\n",
    "#             print(f_local, \"exists\\n\")\n",
    "            pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import utils\n",
    "\n",
    "def y_inverse_transform(y, y_min_max, y_type):\n",
    "    if y.ndim == 1:\n",
    "        y = np.expand_dims(y, axis=0)\n",
    "\n",
    "    y_new = np.zeros_like(y)\n",
    "\n",
    "    for i in xrange(2):\n",
    "        y_new[:, i] = utils.min_max_scale(y[:, i], (0, 1), (y_min_max[0][i], y_min_max[1][i]))\n",
    "\n",
    "    if y_type == 'angle':\n",
    "        y_new[:, 2:] = (y[:, 2:] * 360) % 360\n",
    "    else:\n",
    "        y_new[:, 2:] = y[:, 2:]\n",
    "    return y_new.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from meshNet_loader import ImageProcessor, LabelsParser  #, DataLoader\n",
    "from visualize import imshow\n",
    "# from consts import IMAGE_RANGE\n",
    "import utils\n",
    "from visualize import render_view\n",
    "\n",
    "\n",
    "def render_images(y_true, y_pred, file_urls, nn_distance, idx_list, data, is_interpolation, weights_filename_local):\n",
    "    print(\"render_images: Entered\")\n",
    "\n",
    "    grid_step = data['grid_step']\n",
    "    roi = data['roi']\n",
    "    prefix_str = \"gridStep\" + str(grid_step) + \"_\" + str(roi[0]) + \"_\" + str(roi[1]) + \"_\" + str(roi[2]) + \\\n",
    "        \"_\" + str(roi[3]) + \"_\" + \\\n",
    "        data['x_type'] + \"_\" + (\"geo-interpolation\" if is_interpolation else \"geo_matching\")\n",
    "    \n",
    "    evaluation_visualization_dir = os.path.join(os.path.dirname(weights_filename_local), os.pardir,\n",
    "                                                'evaluations_visualizations')\n",
    "    print('evaluation_visualization_dir:', evaluation_visualization_dir)\n",
    "    if not os.path.exists(evaluation_visualization_dir):\n",
    "        os.makedirs(evaluation_visualization_dir)\n",
    "\n",
    "    for idx in idx_list:\n",
    "        print(\"idx\", idx)\n",
    "        f = file_urls[idx]\n",
    "    \n",
    "        f_local = f.replace('/mnt/arik_2T_usb/project/sessions_outputs', data_sessions_outputs)\n",
    "        if not os.path.isfile(f_local):\n",
    "            print(f_local, \"does not exist\")\n",
    "            continue\n",
    "\n",
    "        \n",
    "#         pose_from_disk = LabelsParser.load_pose_file(f_local)\n",
    "#         y_true_from_disk = np.empty((4,), dtype=np.float32)\n",
    "#         y_true_from_disk[:2] = pose_from_disk[:2]\n",
    "#         y_true_from_disk[2:] = pose_from_disk[3:5]\n",
    "#         print(\"pose_from_disk\", pose_from_disk)\n",
    "#         print(\"y_true_from_disk:\", y_true_from_disk)\n",
    "        yp_true = utils.get_yaw_pitch_from_quaternion_array(y_true[idx][2:])[0]\n",
    "        print(\"yaw, pitch true:\", yp_true)\n",
    "        y_true_cur = np.empty((4,), dtype=np.float32)\n",
    "        y_true_cur[:2] = y_true[idx][:2]\n",
    "        y_true_cur[2:] = yp_true\n",
    "        print(\"y_true_cur\", y_true_cur)\n",
    "        \n",
    "        print(\"y_true:\", y_true[idx])\n",
    "        print(\"y_pred:\", y_pred[idx])\n",
    "        yp_pred = utils.get_yaw_pitch_from_quaternion_array(y_pred[idx][2:])[0]\n",
    "        print(\"yaw, pitch pred:\", yp_pred)\n",
    "        y_pred_cur = np.empty((4,), dtype=np.float32)\n",
    "        y_pred_cur[:2] = y_pred[idx][:2]\n",
    "        y_pred_cur[2:] = yp_pred\n",
    "        print(\"y_pred_cur\", y_pred_cur)\n",
    "\n",
    "        y_true_cur_str = str(y_true_cur[0]) + '_' + str(y_true_cur[1]) + '_' + str(y_true_cur[2]) + '_' + str(y_true_cur[3])\n",
    "        y_pred_cur_str = str(y_pred_cur[0]) + '_' + str(y_pred_cur[1]) + '_' + str(y_pred_cur[2]) + '_' + str(y_pred_cur[3])\n",
    "\n",
    "        if is_interpolation:\n",
    "            x_manhattan_distance = abs(y_true_cur[0] - y_pred_cur[0]) // grid_step\n",
    "            y_manhattan_distance = abs(y_true_cur[1] - y_pred_cur[1]) // grid_step\n",
    "            xy_manhattan_distance = x_manhattan_distance + y_manhattan_distance\n",
    "            dist_str = '_D_' + str(int(xy_manhattan_distance))\n",
    "        else:\n",
    "            dist_str = '_nn_' + str(int(nn_distance[idx]))\n",
    "        print(\"dist_str:\", dist_str)\n",
    "\n",
    "        img_true_path = os.path.join(evaluation_visualization_dir, prefix_str + \"_\" +\n",
    "                                     str(idx) + dist_str + '_img_true_' + y_true_cur_str + \".png\")\n",
    "\n",
    "        img_pred_path = os.path.join(evaluation_visualization_dir, prefix_str + \"_\" +\n",
    "                                     str(idx) + dist_str + '_img_pred_' + y_pred_cur_str + \".png\")\n",
    "        \n",
    "        print(f_local)\n",
    "        img_true_from_disk = ImageProcessor.load_image(f_local, (160, 120))\n",
    "        if img_true_from_disk is not None:\n",
    "            img_true_from_disk = ImageProcessor.flip_imgs_colors(img_true_from_disk)\n",
    "            imshow('img_true_from_disk' + str(idx), img_true_from_disk)\n",
    "\n",
    "        if os.path.exists(img_true_path):\n",
    "            print(\"img_true exists\", img_true_path)\n",
    "        else:\n",
    "            img_true = render_view(y_true_cur)\n",
    "            img_true = ImageProcessor.flip_imgs_colors(img_true)\n",
    "            imshow('img_true_' + str(idx), img_true)\n",
    "            \n",
    "            cv2.imwrite(img_true_path, img_true)\n",
    "            print(\"Wrote img_true:\", img_true_path)\n",
    "        \n",
    "        \n",
    "        if os.path.exists(img_pred_path):\n",
    "            print(\"img_pred exists\", img_pred_path)\n",
    "        else:\n",
    "            img_pred = render_view(y_pred_cur)\n",
    "            img_pred = ImageProcessor.flip_imgs_colors(img_pred)\n",
    "            imshow('img_pred_' + str(idx), img_pred)\n",
    "\n",
    "            cv2.imwrite(img_pred_path, img_pred)\n",
    "            print(\"Wrote img_pred:\", img_pred_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def get_y_min_max_from_log(weights_filename_local):\n",
    "    \n",
    "    log_file_path = os.path.join(os.path.dirname(weights_filename_local), os.pardir, 'logs',\n",
    "                                 'meshNet_console_log.txt')\n",
    "    print('log_file_path:', log_file_path)\n",
    "    \n",
    "    found_line = False\n",
    "    with open(log_file_path) as f:\n",
    "        y_min_max_str = \"\"\n",
    "        for line in f:\n",
    "            if found_line:\n",
    "                y_min_max_str += line\n",
    "                break\n",
    "                \n",
    "            if line.startswith(\"y_min_max\"):\n",
    "                y_min_max_str += line\n",
    "                found_line = True\n",
    "                \n",
    "    if not found_line:\n",
    "        raise Exception(\"Did not find y_min_max in log file\", log_file_path)\n",
    "    \n",
    "    y_min_max_str = y_min_max_str.replace(\" \", \"\")\n",
    "    y_min_max_str = y_min_max_str.replace(\"\\n\", \"\")\n",
    "    \n",
    "    \n",
    "#     print('y_min_max_str', y_min_max_str)\n",
    "\n",
    "#     y_min_max = np.array([[-1600., -800., -0.7071, -0.561, -0.536, -0.4777], \\\n",
    "#                      [-800., 0, 0.5, 0.7934, 0.7934, 0.7071]])\n",
    "#     y_min_max_str y_min_max:(array([-1200.,-400.,-0.7071,-0.561,-0.536,-0.4777],dtype=float32),array([-800.,0.,0.5,0.7934,0.7934,0.7071],dtype=float32))\n",
    "    \n",
    "    numbers_mask = re.compile(r\"[+-]?\\d+(?:\\.\\d+)?\")\n",
    "\n",
    "    newtext = y_min_max_str\n",
    "    mtch = numbers_mask.search(newtext)\n",
    "    numbers = []\n",
    "    while mtch:\n",
    "        num = mtch.group(0)\n",
    "#         print('match: %s' % (num))\n",
    "        numbers.append(num)\n",
    "        newtext = newtext[mtch.end(0) + 1:]\n",
    "        mtch = numbers_mask.search(newtext)\n",
    "\n",
    "#     print(numbers)\n",
    "\n",
    "    numbers = np.array(numbers, dtype=np.float32)\n",
    "#     print(numbers)\n",
    "\n",
    "    y_min_max = np.empty((2, 6), dtype=np.float32)\n",
    "    y_min_max[0, :] = numbers[:6]\n",
    "    y_min_max[1, :] = numbers[7:13]\n",
    "    \n",
    "    print('y_min_max:', y_min_max)\n",
    "    return y_min_max\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from meshNet_loader import process_labels\n",
    "\n",
    "if os.path.exists('sorting_cache.pkl'):\n",
    "    print('sorting_cache.pkl exists. Loading...')\n",
    "    with open('sorting_cache.pkl', 'rb') as f:\n",
    "        sorting_cache = pickle.load(f)\n",
    "else:\n",
    "    sorting_cache = {}\n",
    "\n",
    "\n",
    "def visualize_evaluation(cur_pkl):\n",
    "    global sorting_cache\n",
    "\n",
    "    with open(cur_pkl, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "        \n",
    "#     print(\"data fields:\")\n",
    "#     for key in data.keys():\n",
    "#         print(\"    \", key)\n",
    "\n",
    "    mesh_name = data['mesh_name']\n",
    "    roi = data['roi']\n",
    "    x_type = data['x_type']\n",
    "    y_type = data['y_type']\n",
    "    weights_filename = data['weights_filename']\n",
    "    weights_filename_local = os.path.join(os.path.dirname(cur_pkl), os.path.pardir, 'hdf5', os.path.split(weights_filename)[1])\n",
    "\n",
    "    print(\"mesh_name:\", mesh_name)\n",
    "    print('roi:', roi)\n",
    "    print('grid_step:', data['grid_step'])\n",
    "    print(\"x_type:\", x_type)\n",
    "    print(\"y_type:\", y_type)\n",
    "    print(\"weights_filename:\", weights_filename)\n",
    "    print(\"weights_filename_local:\", weights_filename_local)\n",
    "\n",
    "    if os.path.isfile(weights_filename_local):\n",
    "        print(\"Local weight available\")\n",
    "    else:\n",
    "        print(\"Local weight NOT found\")\n",
    "    \n",
    "    is_interpolation = True if cur_pkl.find('val_loss') != -1 else False\n",
    "    \n",
    "    use_cache = False\n",
    "    # Simple cache for debug\n",
    "    if use_cache and weights_filename_local in sorting_cache:\n",
    "        print(\"Using cache_sorted_array_idx\")\n",
    "        sorted_array_idx = sorting_cache[weights_filename_local]\n",
    "    else:        \n",
    "        sorted_array_idx = get_sorted_array_idx(data, is_interpolation)\n",
    "        # Update cache\n",
    "        sorting_cache[weights_filename_local] = sorted_array_idx\n",
    "        \n",
    "    if is_interpolation:\n",
    "        file_urls = data['file_urls_test'][sorted_array_idx]\n",
    "        y_true = data['y_test_true'][sorted_array_idx]\n",
    "        y_pred = data['y_test_pred'][sorted_array_idx]\n",
    "    else:\n",
    "        file_urls = data['file_urls_train'][sorted_array_idx]\n",
    "        y_true = data['y_train_true'][sorted_array_idx]\n",
    "        y_pred = data['y_train_pred'][sorted_array_idx]\n",
    "        \n",
    "    idx_list = range(20)    \n",
    "    idx_list += range(45, 55)\n",
    "    idx_list += range(99, 105)\n",
    "    idx_list += range(995, 1005)\n",
    "    idx_list += range(4995, 5005)\n",
    "    idx_list += range(49995, 50005)\n",
    "    idx_list += range(len(file_urls)-20, len(file_urls))\n",
    "    \n",
    "    valid_idx_list = []\n",
    "    for idx in idx_list:\n",
    "        if idx < len(file_urls):\n",
    "            valid_idx_list.append(idx)\n",
    "    idx_list = valid_idx_list\n",
    "            \n",
    "#     print(\"file_urls len:\", len(file_urls), \"idx_list:\", idx_list)\n",
    "    \n",
    "    verify_images_availability(file_urls, idx_list)\n",
    "\n",
    "    if is_interpolation:\n",
    "        nn_distance = None\n",
    "    else:\n",
    "        nn_distance = nn_dist[sorted_array_idx]\n",
    "    \n",
    "#     y_min_max = get_y_min_max_from_log(weights_filename_local)\n",
    "    render_images(y_true, y_pred, file_urls, nn_distance, idx_list, data, is_interpolation, weights_filename_local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main\n",
    "\n",
    "grid_step_10_path = os.path.join(results_dir, 'gridStep10')\n",
    "grid_step_20_path = os.path.join(results_dir, 'gridStep20')\n",
    "grid_step_40_path = os.path.join(results_dir, 'gridStep40')\n",
    "\n",
    "\n",
    "pkl_list_10 = get_files_with_ext(grid_step_10_path, ext_list=('.pkl'), recursive=True, abs_path=True,\n",
    "                                 sort=True, warn_empty=True)\n",
    "pkl_list_20 = get_files_with_ext(grid_step_20_path, ext_list=('.pkl'), recursive=True, abs_path=True,\n",
    "                                 sort=True, warn_empty=True)\n",
    "pkl_list_40 = get_files_with_ext(grid_step_40_path, ext_list=('.pkl'), recursive=True, abs_path=True,\n",
    "                                 sort=True, warn_empty=True)\n",
    "\n",
    "print('pkl_list_10:', len(pkl_list_10))\n",
    "print('pkl_list_20:', len(pkl_list_20))\n",
    "print('pkl_list_40:', len(pkl_list_40))\n",
    "all_pkl = pkl_list_10 + pkl_list_20 + pkl_list_40\n",
    "print(len(all_pkl))\n",
    "\n",
    "for idx, pkl in enumerate(all_pkl):\n",
    "    print('Start pkl idx', idx, \", pkl:\", pkl)\n",
    "    visualize_evaluation(pkl)\n",
    "    print('Done pkl idx', idx, '\\n\\n\\n')\n",
    "    \n",
    "#     break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Invert colors for \"evaluations_visualizations\"\n",
    "#\n",
    "\n",
    "grid_step_10_path = os.path.join(results_dir, 'gridStep10')\n",
    "grid_step_20_path = os.path.join(results_dir, 'gridStep20')\n",
    "grid_step_40_path = os.path.join(results_dir, 'gridStep40')\n",
    "\n",
    "\n",
    "img_list_10 = get_files_with_ext(grid_step_10_path, ext_list=('.png'), recursive=True, abs_path=True,\n",
    "                                 sort=True, warn_empty=True)\n",
    "img_list_20 = get_files_with_ext(grid_step_20_path, ext_list=('.png'), recursive=True, abs_path=True,\n",
    "                                 sort=True, warn_empty=True)\n",
    "img_list_40 = get_files_with_ext(grid_step_40_path, ext_list=('.png'), recursive=True, abs_path=True,\n",
    "                                 sort=True, warn_empty=True)\n",
    "\n",
    "print('img_list_10:', len(img_list_10))\n",
    "print('img_list_20:', len(img_list_20))\n",
    "print('img_list_40:', len(img_list_40))\n",
    "all_imgs = img_list_10 + img_list_20 + img_list_40\n",
    "print(len(all_imgs))\n",
    "\n",
    "# Choose only images of \"evaluations_visualizations\"\n",
    "idx_list = []\n",
    "for idx, fname in enumerate(all_imgs):\n",
    "    idx_list.append(True if \"evaluations_visualizations\" in fname else False)\n",
    "idx_list = np.array(idx_list)\n",
    "all_imgs = np.array(all_imgs)\n",
    "all_imgs = all_imgs[idx_list]\n",
    "print('evaluation visualization imgs number:', len(all_imgs))\n",
    "\n",
    "print(\"Inverting evaluation visualization images colors...\")\n",
    "for idx, fname in enumerate(all_imgs):\n",
    "    print('idx:', idx, 'fname:', fname)    \n",
    "    \n",
    "    img = cv2.imread(fname, cv2.IMREAD_GRAYSCALE)\n",
    "    img = ImageProcessor.flip_imgs_colors(img)\n",
    "    new_fname = os.path.join(os.path.dirname(fname), 'white', os.path.basename(fname))\n",
    "    mkdirs(os.path.dirname(new_fname))\n",
    "    cv2.imwrite(new_fname, img)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(all_pkl))\n",
    "print(type(all_pkl))\n",
    "print(type(all_pkl))\n",
    "\n",
    "print(all_pkl[0])\n",
    "\n",
    "\n",
    "idx_list = []\n",
    "for idx, pkl in enumerate(all_pkl):\n",
    "    if \"evaluations_visualizations\" not in pkl:\n",
    "        print(\"NO\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for cnt, f in enumerate(file_urls_test_sorted):\n",
    "#     if cnt % 100 != 0:\n",
    "#         continue\n",
    "    \n",
    "    src = f\n",
    "    dst = f.replace('/mnt/arik_2T_usb/project/sessions_outputs', data_sessions_outputs)\n",
    "#     print(\"dst\", dst)\n",
    "    if not os.path.isfile(dst):\n",
    "        dst_dir = os.path.split(dst)[0] + os.sep + os.pardir\n",
    "        mkdirs(dst_dir)\n",
    "        src_dir = os.path.split(src)[0]\n",
    "#         cmd = [\"scp\", \"-r\", \"arik@194.153.101.19:\" + src_dir, dst_dir]\n",
    "#         print(cmd)\n",
    "#         p = subprocess.Popen(cmd)\n",
    "        scp_expect(\"arik@194.153.101.19:\" + src_dir, dst_dir)\n",
    "        \n",
    "#         sts = os.waitpid(p.pid, 0)\n",
    "        print(cnt, dst_dir)\n",
    "        print()\n",
    "#         break\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Copies from remote but asks for password\n",
    "\n",
    "import subprocess\n",
    "# Shamir#2017!\n",
    "\n",
    "for cnt, f in enumerate(file_urls_test_sorted):\n",
    "    if cnt % 100 != 0:\n",
    "        continue\n",
    "    \n",
    "    src = f\n",
    "    dst = f.replace('/mnt/arik_2T_usb/project/sessions_outputs', data_sessions_outputs)\n",
    "#     print(\"dst\", dst)\n",
    "    if not os.path.isfile(dst):\n",
    "        dst_dir = os.path.split(dst)[0] + os.sep + os.pardir\n",
    "        mkdirs(dst_dir)\n",
    "        src_dir = os.path.split(src)[0]\n",
    "        cmd = [\"scp\", \"-r\", \"arik@194.153.101.19:\" + src_dir, dst_dir]\n",
    "        print(cmd)\n",
    "        p = subprocess.Popen(cmd)\n",
    "        \n",
    "        sts = os.waitpid(p.pid, 0)\n",
    "        print(cnt)\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print(\"file_urls_test_sorted length \", len(file_urls_test_sorted))\n",
    "cnt = 0\n",
    "for f in file_urls_test_sorted:\n",
    "    dst = f.replace('/mnt/arik_2T_usb/project/sessions_outputs', data_sessions_outputs)\n",
    "    if os.path.isfile(dst):\n",
    "        cnt +=1\n",
    "        if cnt % 500 == 0:\n",
    "            print(\"dst\", dst)\n",
    "        \n",
    "print(\"files number available\", cnt, \", precent \", cnt / len(file_urls_test_sorted))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import meshNet_model\n",
    "import meshNet_loader\n",
    "import resnet50\n",
    "import cv2\n",
    "\n",
    "params = {'image_shape': (120, 160, 1), 'xy_nb_outs': 2, 'rot_nb_outs': 4, 'multi_gpu': False}\n",
    "model, model_name = resnet50.resnet50_regression_train(**params)\n",
    "\n",
    "meshNet_model.load_model_weights(model, weights_filename_local)\n",
    "\n",
    "# test_scores = model.evaluate(loader.x_test, [loader.y_test[:, :2], loader.y_test[:, 2:]],\n",
    "#                              batch_size=batch_size, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from meshNet_loader import ImageProcessor, LabelsParser, DataLoader\n",
    "from visualize import imshow\n",
    "from consts import IMAGE_RANGE\n",
    "import utils\n",
    "from visualize import render_view\n",
    "\n",
    "# Taken from log file\n",
    "y_min_max = np.array([[-1600., -800., -0.7071, -0.561, -0.536, -0.4777], \\\n",
    "                     [-800., 0, 0.5, 0.7934, 0.7934, 0.7071]])\n",
    "print(\"y_min_max\", y_min_max)\n",
    "\n",
    "print(\"x_type\", x_type)\n",
    "for idx, f in enumerate(file_urls_test_sorted):\n",
    "    if idx % 50 != 0:\n",
    "        continue\n",
    "\n",
    "    if idx % 100 == 0:\n",
    "        continue\n",
    "    \n",
    "    print(\"idx\", idx)\n",
    "    \n",
    "    f_local = f.replace('/mnt/arik_2T_usb/project/sessions_outputs', data_sessions_outputs)\n",
    "    if not os.path.isfile(f_local):\n",
    "        print(f_local, \"does not exist\")\n",
    "        continue\n",
    "        \n",
    "    print(f_local)\n",
    "    img = ImageProcessor.load_image(f_local, (160, 120))\n",
    "    img = ImageProcessor.flip_imgs_colors(img)\n",
    "    \n",
    "    pose = LabelsParser.load_pose_file(f_local)\n",
    "    print(\"GT pose\", pose)\n",
    "    y_true = np.empty((4,), dtype=np.float32)\n",
    "    y_true[:2] = pose[:2]\n",
    "    y_true[2:] = pose[3:5]\n",
    "    print(\"y_true\", y_true)\n",
    "    \n",
    "#     imshow('aa', img)\n",
    "\n",
    "    x = np.expand_dims(img, axis=0).astype(np.float32)\n",
    "    \n",
    "    print(x.shape)\n",
    "    x = utils.min_max_scale(x, IMAGE_RANGE, (0, 1))\n",
    "    res = model.predict(x, batch_size=1, verbose=1)\n",
    "    print(res)\n",
    "    \n",
    "    y = np.empty((6,), dtype=np.float32)\n",
    "    y[0:2] = res[0][0][0:2]\n",
    "    y[2:6] = res[1][0][0:4]\n",
    "    print(y)\n",
    "    y_pred_q = y_inverse_transform(y, y_min_max, y_type)\n",
    "    print(\"y_pred_q\", y_pred_q)\n",
    "    \n",
    "    yp = utils.get_yaw_pitch_from_quaternion_array(y_pred_q[2:])[0]\n",
    "    print(\"yaw, pitch \", yp)\n",
    "\n",
    "    y_pred = np.empty((4,), dtype=np.float32)\n",
    "    y_pred[:2] = y_pred_q[:2]\n",
    "    y_pred[2:] = yp[:2]\n",
    "    \n",
    "    print(\"y_pred\", y_pred)\n",
    "    print(\"y_true\", y_true)    \n",
    "\n",
    "    img_true = render_view(y_true)\n",
    "    img_true = ImageProcessor.flip_imgs_colors(img_true)\n",
    "    imshow('img_true_' + str(idx), img_true)\n",
    "\n",
    "    img_pred = render_view(y_pred)\n",
    "    img_pred = ImageProcessor.flip_imgs_colors(img_pred)\n",
    "    imshow('img_pred_' + str(idx), img_pred)\n",
    "\n",
    "    y_true_str = str(y_true[0]) + '_' + str(y_true[1]) + '_' + str(y_true[2]) + '_' + str(y_true[3])\n",
    "    y_pred_str = str(y_pred[0]) + '_' + str(y_pred[1]) + '_' + str(y_pred[2]) + '_' + str(y_pred[3])\n",
    "    \n",
    "    dist = xy_manhattan_distance[sorted_array_idx][idx]\n",
    "    dist_str = '_D_' + str(int(dist))\n",
    "    cv2.imwrite(str(idx) + dist_str + '_img_true_' + y_true_str + \".png\", img_true)\n",
    "    cv2.imwrite(str(idx) + dist_str + '_img_pred_' + y_pred_str + \".png\", img_pred)\n",
    "    \n",
    "#     break\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
